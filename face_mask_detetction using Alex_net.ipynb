{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62df2b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input,Dense,Conv2D,MaxPooling2D,Flatten,BatchNormalization,Dropout\n",
    "\n",
    "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c9af700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4541d20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen=ImageDataGenerator( rotation_range=45,\n",
    "    width_shift_range=0.4,\n",
    "    height_shift_range=0.4,\n",
    "    brightness_range=[-0.2,1.5],\n",
    "    shear_range=4,\n",
    "    rescale=1./255)\n",
    "\n",
    "\n",
    "test_gen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d6b00fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7041bf10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 600 images belonging to 2 classes.\n",
      "Found 306 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "final_train_gen=train_gen.flow_from_directory(r\"F:\\Arifa\\face mask detection dataset\\New Masks Dataset\\Train\",\n",
    "                                              target_size=(227,227),class_mode=\"sparse\",batch_size=32)\n",
    "\n",
    "final_test_gen=test_gen.flow_from_directory(r\"F:\\Arifa\\face mask detection dataset\\New Masks Dataset\\Validation\",\n",
    "                                            target_size=(227,227),class_mode=\"sparse\",batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84d05583",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb90b360",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer=Input(shape=(227,227,3))\n",
    "conv_1=Conv2D(96,(11,11),strides=(4,4),padding=\"valid\",activation=\"relu\")(input_layer)\n",
    "max_p1=MaxPooling2D(pool_size=(3,3),strides=2,padding=\"valid\")(conv_1)\n",
    "bn1=BatchNormalization()(max_p1)\n",
    "\n",
    "conv_2=Conv2D(256,(5,5),strides=(1,1),padding=\"same\",activation=\"relu\")(bn1)\n",
    "max_p2=MaxPooling2D(pool_size=(3,3),strides=2,padding=\"valid\")(conv_2)\n",
    "bn2=BatchNormalization()(max_p2)\n",
    "\n",
    "conv_3=Conv2D(384,(3,3),strides=(1,1),padding=\"same\",activation=\"relu\")(bn2)\n",
    "bn3=BatchNormalization()(conv_3)\n",
    "\n",
    "\n",
    "conv_4=Conv2D(384,(3,3),strides=(1,1),padding=\"same\",activation=\"relu\")(bn3)\n",
    "bn4=BatchNormalization()(conv_4)\n",
    "\n",
    "conv_5=Conv2D(256,(3,3),strides=(1,1),padding=\"same\",activation=\"relu\")(bn4)\n",
    "max_p3=MaxPooling2D(pool_size=(3,3),strides=2,padding=\"valid\")(conv_5)\n",
    "bn5=BatchNormalization()(max_p3)\n",
    "\n",
    "\n",
    "flatten=Flatten()(bn5)\n",
    "\n",
    "\n",
    "hidd_1=Dense(4096,activation=\"relu\")(flatten)\n",
    "d1=Dropout(rate=0.5)(hidd_1)\n",
    "\n",
    "hidd_2=Dense(4096,activation=\"relu\")(d1)\n",
    "d2=Dropout(rate=0.5)(hidd_2)\n",
    "\n",
    "output_layer=Dense(2,activation=\"softmax\")(d2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f544451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alex_net=Model(inputs=input_layer,outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "612ebf94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">227</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">227</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">34,944</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">614,656</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">885,120</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,327,488</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">884,992</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9216</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)                │      <span style=\"color: #00af00; text-decoration-color: #00af00\">37,752,832</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)                │      <span style=\"color: #00af00; text-decoration-color: #00af00\">16,781,312</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,194</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m227\u001b[0m, \u001b[38;5;34m227\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │          \u001b[38;5;34m34,944\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │             \u001b[38;5;34m384\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m614,656\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m384\u001b[0m)         │         \u001b[38;5;34m885,120\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m384\u001b[0m)         │           \u001b[38;5;34m1,536\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m384\u001b[0m)         │       \u001b[38;5;34m1,327,488\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m384\u001b[0m)         │           \u001b[38;5;34m1,536\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m884,992\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9216\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)                │      \u001b[38;5;34m37,752,832\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)                │      \u001b[38;5;34m16,781,312\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │           \u001b[38;5;34m8,194\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">58,295,042</span> (222.38 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m58,295,042\u001b[0m (222.38 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">58,292,290</span> (222.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m58,292,290\u001b[0m (222.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,752</span> (10.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,752\u001b[0m (10.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alex_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05b3372b",
   "metadata": {},
   "outputs": [],
   "source": [
    "alex_net.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1f4d5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping,ModelCheckpoint,CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4839701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# es=EarlyStopping(monitor=\"val_loss\",min_delta=0.0001,patience=0,verbose=1,start_from_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e18cf542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mc=ModelCheckpoint(r\"F:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model{loss:02f}.keras\",monitor=\"val_loss\",verbose=1,save_freq=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72e37cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv=CSVLogger(r\"F:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\models_perf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75818e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alex_net.fit(final_train_gen,steps_per_epoch= 10000//40,epochs=500,validation_data=final_test_gen,validation_steps=800//40,callbacks=[es,mc,csv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48d28b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afrin\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:07\u001b[0m 3s/step - accuracy: 0.5087 - loss: 16.5394"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afrin\\anaconda3\\Lib\\contextlib.py:155: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model15.155516.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 312ms/step - accuracy: 0.5268 - loss: 15.2607 - val_accuracy: 0.5000 - val_loss: 242.4516\n",
      "Epoch 2/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:51\u001b[0m 3s/step - accuracy: 0.5120 - loss: 6.6653\n",
      "Epoch 2: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model6.715656.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 300ms/step - accuracy: 0.5163 - loss: 6.7118 - val_accuracy: 0.5000 - val_loss: 116.4129\n",
      "Epoch 3/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:57\u001b[0m 3s/step - accuracy: 0.5353 - loss: 4.9466\n",
      "Epoch 3: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model4.052803.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 303ms/step - accuracy: 0.5381 - loss: 4.1207 - val_accuracy: 0.5065 - val_loss: 18.5123\n",
      "Epoch 4/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:58\u001b[0m 3s/step - accuracy: 0.5791 - loss: 1.9091\n",
      "Epoch 4: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model1.697276.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 302ms/step - accuracy: 0.5661 - loss: 1.7134 - val_accuracy: 0.4935 - val_loss: 4.7087\n",
      "Epoch 5/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:01\u001b[0m 3s/step - accuracy: 0.5537 - loss: 1.2330\n",
      "Epoch 5: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model1.029562.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 304ms/step - accuracy: 0.5888 - loss: 1.0450 - val_accuracy: 0.5359 - val_loss: 3.3325\n",
      "Epoch 6/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:19\u001b[0m 3s/step - accuracy: 0.5621 - loss: 0.9685\n",
      "Epoch 6: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.941803.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 380ms/step - accuracy: 0.5617 - loss: 0.9438 - val_accuracy: 0.5131 - val_loss: 1.7114\n",
      "Epoch 7/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:38\u001b[0m 3s/step - accuracy: 0.5592 - loss: 0.8331\n",
      "Epoch 7: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.812120.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 350ms/step - accuracy: 0.5723 - loss: 0.8137 - val_accuracy: 0.5163 - val_loss: 1.5794\n",
      "Epoch 8/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:27\u001b[0m 3s/step - accuracy: 0.6301 - loss: 0.7497\n",
      "Epoch 8: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.691038.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 370ms/step - accuracy: 0.6546 - loss: 0.6955 - val_accuracy: 0.5131 - val_loss: 1.5134\n",
      "Epoch 9/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:48\u001b[0m 3s/step - accuracy: 0.6336 - loss: 0.6861\n",
      "Epoch 9: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.711565.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 353ms/step - accuracy: 0.6272 - loss: 0.7096 - val_accuracy: 0.5948 - val_loss: 0.6927\n",
      "Epoch 10/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:00\u001b[0m 3s/step - accuracy: 0.6400 - loss: 0.6440\n",
      "Epoch 10: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.669105.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 372ms/step - accuracy: 0.6231 - loss: 0.6672 - val_accuracy: 0.6307 - val_loss: 0.6797\n",
      "Epoch 11/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:04\u001b[0m 3s/step - accuracy: 0.6372 - loss: 0.6493\n",
      "Epoch 11: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.635623.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 352ms/step - accuracy: 0.6444 - loss: 0.6367 - val_accuracy: 0.5229 - val_loss: 1.0288\n",
      "Epoch 12/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:54\u001b[0m 3s/step - accuracy: 0.6637 - loss: 0.6414\n",
      "Epoch 12: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.627278.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 344ms/step - accuracy: 0.6680 - loss: 0.6284 - val_accuracy: 0.5131 - val_loss: 1.2285\n",
      "Epoch 13/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:41\u001b[0m 3s/step - accuracy: 0.6845 - loss: 0.6482\n",
      "Epoch 13: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.641173.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 281ms/step - accuracy: 0.6911 - loss: 0.6417 - val_accuracy: 0.5294 - val_loss: 0.8449\n",
      "Epoch 14/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:11\u001b[0m 3s/step - accuracy: 0.6735 - loss: 0.6768\n",
      "Epoch 14: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.671984.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 284ms/step - accuracy: 0.6656 - loss: 0.6724 - val_accuracy: 0.5458 - val_loss: 0.7949\n",
      "Epoch 15/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:37\u001b[0m 3s/step - accuracy: 0.6403 - loss: 0.6229\n",
      "Epoch 15: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.630441.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 314ms/step - accuracy: 0.6631 - loss: 0.6299 - val_accuracy: 0.7288 - val_loss: 0.5322\n",
      "Epoch 16/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:57\u001b[0m 3s/step - accuracy: 0.6440 - loss: 0.6487\n",
      "Epoch 16: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.641790.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 301ms/step - accuracy: 0.6665 - loss: 0.6423 - val_accuracy: 0.7908 - val_loss: 0.4912\n",
      "Epoch 17/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:58\u001b[0m 3s/step - accuracy: 0.6212 - loss: 0.6542\n",
      "Epoch 17: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.662260.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 302ms/step - accuracy: 0.6324 - loss: 0.6617 - val_accuracy: 0.5458 - val_loss: 0.8347\n",
      "Epoch 18/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:03\u001b[0m 3s/step - accuracy: 0.6425 - loss: 0.6178\n",
      "Epoch 18: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.643182.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 303ms/step - accuracy: 0.6371 - loss: 0.6413 - val_accuracy: 0.7712 - val_loss: 0.4846\n",
      "Epoch 19/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:00\u001b[0m 3s/step - accuracy: 0.6482 - loss: 0.6111\n",
      "Epoch 19: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.609247.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 306ms/step - accuracy: 0.6499 - loss: 0.6094 - val_accuracy: 0.7843 - val_loss: 0.4782\n",
      "Epoch 20/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:28\u001b[0m 3s/step - accuracy: 0.6983 - loss: 0.6220\n",
      "Epoch 20: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.618244.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 313ms/step - accuracy: 0.6814 - loss: 0.6185 - val_accuracy: 0.7778 - val_loss: 0.5186\n",
      "Epoch 21/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:59\u001b[0m 3s/step - accuracy: 0.6733 - loss: 0.5917\n",
      "Epoch 21: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.614721.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 305ms/step - accuracy: 0.6703 - loss: 0.6130 - val_accuracy: 0.5817 - val_loss: 0.6681\n",
      "Epoch 22/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:56\u001b[0m 3s/step - accuracy: 0.6425 - loss: 0.6049\n",
      "Epoch 22: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.584451.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 300ms/step - accuracy: 0.6787 - loss: 0.5860 - val_accuracy: 0.8333 - val_loss: 0.4458\n",
      "Epoch 23/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:57\u001b[0m 3s/step - accuracy: 0.7228 - loss: 0.5372\n",
      "Epoch 23: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.603961.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 302ms/step - accuracy: 0.6894 - loss: 0.5989 - val_accuracy: 0.7484 - val_loss: 0.5265\n",
      "Epoch 24/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:55\u001b[0m 3s/step - accuracy: 0.7039 - loss: 0.5600\n",
      "Epoch 24: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.589262.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 300ms/step - accuracy: 0.6911 - loss: 0.5870 - val_accuracy: 0.8007 - val_loss: 0.4357\n",
      "Epoch 25/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:09\u001b[0m 3s/step - accuracy: 0.6610 - loss: 0.6603\n",
      "Epoch 25: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.617180.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 304ms/step - accuracy: 0.6662 - loss: 0.6205 - val_accuracy: 0.6830 - val_loss: 0.5459\n",
      "Epoch 26/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:19\u001b[0m 3s/step - accuracy: 0.6891 - loss: 0.5773\n",
      "Epoch 26: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.618975.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 314ms/step - accuracy: 0.6684 - loss: 0.6158 - val_accuracy: 0.5196 - val_loss: 0.8168\n",
      "Epoch 27/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:10\u001b[0m 3s/step - accuracy: 0.6698 - loss: 0.6086\n",
      "Epoch 27: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.607064.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 326ms/step - accuracy: 0.6530 - loss: 0.6072 - val_accuracy: 0.5000 - val_loss: 1.2454\n",
      "Epoch 28/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:00\u001b[0m 3s/step - accuracy: 0.6902 - loss: 0.6014\n",
      "Epoch 28: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.651590.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 305ms/step - accuracy: 0.6438 - loss: 0.6478 - val_accuracy: 0.7843 - val_loss: 0.5560\n",
      "Epoch 29/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:07\u001b[0m 3s/step - accuracy: 0.6636 - loss: 0.6263\n",
      "Epoch 29: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.613188.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 305ms/step - accuracy: 0.6942 - loss: 0.6142 - val_accuracy: 0.5163 - val_loss: 1.0958\n",
      "Epoch 30/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:00\u001b[0m 3s/step - accuracy: 0.6879 - loss: 0.6101\n",
      "Epoch 30: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.607128.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 349ms/step - accuracy: 0.6806 - loss: 0.6074 - val_accuracy: 0.5196 - val_loss: 1.0718\n",
      "Epoch 31/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:57\u001b[0m 3s/step - accuracy: 0.6670 - loss: 0.6862\n",
      "Epoch 31: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.673609.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 304ms/step - accuracy: 0.6667 - loss: 0.6746 - val_accuracy: 0.8431 - val_loss: 0.3967\n",
      "Epoch 32/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:04\u001b[0m 3s/step - accuracy: 0.6891 - loss: 0.5945\n",
      "Epoch 32: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.586917.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 306ms/step - accuracy: 0.6899 - loss: 0.5875 - val_accuracy: 0.8170 - val_loss: 0.4382\n",
      "Epoch 33/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:52\u001b[0m 3s/step - accuracy: 0.6950 - loss: 0.6073\n",
      "Epoch 33: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.591636.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 300ms/step - accuracy: 0.6919 - loss: 0.5928 - val_accuracy: 0.7908 - val_loss: 0.5106\n",
      "Epoch 34/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:57\u001b[0m 3s/step - accuracy: 0.6774 - loss: 0.5881\n",
      "Epoch 34: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.585848.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 305ms/step - accuracy: 0.6767 - loss: 0.5860 - val_accuracy: 0.8595 - val_loss: 0.3942\n",
      "Epoch 35/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:55\u001b[0m 3s/step - accuracy: 0.6954 - loss: 0.5615\n",
      "Epoch 35: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.584490.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 302ms/step - accuracy: 0.6843 - loss: 0.5827 - val_accuracy: 0.6830 - val_loss: 0.8421\n",
      "Epoch 36/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:37\u001b[0m 3s/step - accuracy: 0.7072 - loss: 0.5879\n",
      "Epoch 36: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.609387.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 337ms/step - accuracy: 0.6867 - loss: 0.6078 - val_accuracy: 0.8170 - val_loss: 0.4466\n",
      "Epoch 37/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:18\u001b[0m 3s/step - accuracy: 0.6677 - loss: 0.5692\n",
      "Epoch 37: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.582333.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 309ms/step - accuracy: 0.6806 - loss: 0.5813 - val_accuracy: 0.4641 - val_loss: 1.3399\n",
      "Epoch 38/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:34\u001b[0m 3s/step - accuracy: 0.6690 - loss: 0.6682\n",
      "Epoch 38: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.656097.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 323ms/step - accuracy: 0.6545 - loss: 0.6570 - val_accuracy: 0.5000 - val_loss: 1.7607\n",
      "Epoch 39/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:59\u001b[0m 3s/step - accuracy: 0.6913 - loss: 0.5915\n",
      "Epoch 39: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.586853.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 304ms/step - accuracy: 0.6685 - loss: 0.5872 - val_accuracy: 0.6765 - val_loss: 0.8352\n",
      "Epoch 40/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:25\u001b[0m 3s/step - accuracy: 0.6930 - loss: 0.5845\n",
      "Epoch 40: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.582575.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 323ms/step - accuracy: 0.6841 - loss: 0.5827 - val_accuracy: 0.6961 - val_loss: 0.5904\n",
      "Epoch 41/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15:46\u001b[0m 4s/step - accuracy: 0.6478 - loss: 0.6466\n",
      "Epoch 41: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.617367.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 511ms/step - accuracy: 0.6760 - loss: 0.6196 - val_accuracy: 0.6765 - val_loss: 0.6895\n",
      "Epoch 42/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:22\u001b[0m 3s/step - accuracy: 0.6679 - loss: 0.6390\n",
      "Epoch 42: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.627434.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 328ms/step - accuracy: 0.6606 - loss: 0.6283 - val_accuracy: 0.5000 - val_loss: 0.9282\n",
      "Epoch 43/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:59\u001b[0m 3s/step - accuracy: 0.6870 - loss: 0.6129\n",
      "Epoch 43: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.643249.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 304ms/step - accuracy: 0.6790 - loss: 0.6409 - val_accuracy: 0.4085 - val_loss: 0.8750\n",
      "Epoch 44/50\n",
      "\u001b[1m 19/250\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:56\u001b[0m 3s/step - accuracy: 0.7231 - loss: 0.5588\n",
      "Epoch 44: saving model to E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\\model0.556150.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 301ms/step - accuracy: 0.7202 - loss: 0.5564 - val_accuracy: 0.7745 - val_loss: 0.5456\n",
      "Epoch 44: early stopping\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger\n",
    "\n",
    "# Define the directory path\n",
    "checkpoint_dir = r\"E:\\Arifa\\face_mask detection\\model_checkpoint face_mask\"\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Define the callbacks\n",
    "es = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "mc = ModelCheckpoint(\n",
    "    filepath=os.path.join(checkpoint_dir, \"model{loss:02f}.keras\"),\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=1,\n",
    "    save_freq=\"epoch\"\n",
    ")\n",
    "csv = CSVLogger(os.path.join(checkpoint_dir, \"models_perf.csv\"))\n",
    "\n",
    "# Train the model\n",
    "history = alex_net.fit(\n",
    "    final_train_gen,\n",
    "    steps_per_epoch=10000 // 40,  # 250 steps per epoch\n",
    "    epochs=50,  # Train for 500 epochs\n",
    "    validation_data=final_test_gen,\n",
    "    validation_steps=800 // 40,  # 20 validation steps\n",
    "    callbacks=[es, mc, csv]  # List of callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f0c09a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44e5c797",
   "metadata": {},
   "outputs": [],
   "source": [
    "#img=cv2.imread(r\"F:\\Arifa\\face mask detection dataset\\New Masks Dataset\\Test\\Non Mask\\real_01032.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "850926e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(r\"F:\\Arifa\\face mask detection dataset\\New Masks Dataset\\Test\\Mask\\2187.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "06fac4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 227, 227, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.resize(img,(227,227))[np.newaxis].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7ba38d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(alex_net.predict(cv2.resize(img,(227,227))[np.newaxis]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "92013435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mask': 0, 'Non Mask': 1}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_train_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4a0a874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#face_model=cv2.CascadeClassifier(r\"C:\\Users\\Afrin\\Downloads\\haarcascade_frontalface_alt.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "71b22114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n"
     ]
    }
   ],
   "source": [
    "face_model=cv2.CascadeClassifier(r\"F:\\Arifa\\haarcascade_frontalface_default.xml\")\n",
    "for x,y,w,h in face_model.detectMultiScale(img):\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),1)\n",
    "    \n",
    "    \n",
    "    if np.argmax(alex_net.predict(cv2.resize(img,(227,227))[np.newaxis]))==0:\n",
    "        cv2.putText(img,'Mask',(x+10,y+10),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0))\n",
    "        cv2.putText(img,'Mask',(x+10,y+10),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0))\n",
    "    else:\n",
    "        cv2.putText(img,'without Mask',(x+10,y+10),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e8656ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"im\",img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f4aeb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558d78cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
